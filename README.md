# Multimodal Depression Screening

This repository contains code for a multimodal facial emotion recognition model for early depression screening, using text, audio, and visual features from the DAIC and EDAIC datasets.

---

## ðŸŸ¢ Getting Started: Python Environment Setup

Follow these steps to set up your development environment.

### 1. Clone the repository

```bash
git clone <repository-url>
cd <repository-directory>
```

### 2. Create a virtual environment

```bash
mkdir .venv
virtualenv .venv
```

### 3. Activate the virtual environment

Linux/macOS
```bash
source .venv/bin/activate
```

Windows
```cmd
.venv\Scripts\activate
```

### 4. Install project dependencies

```bash
pip install -r requirements.txt
```

---

# Dataset Notice

This project depends on the **DAIC and EDAIC datasets**, which are **not included**.  

- You must obtain the datasets separately under their respective End-User License Agreements:
  - [DAIC Dataset EULA](https://dcapswoz.ict.usc.edu/daic-woz-database-download/)
  - [EDAIC Dataset EULA](https://dcapswoz.ict.usc.edu/extended-daic-database-download/)
- Redistribution of these datasets or any portion of them is **strictly prohibited**.
- Use of this project for **commercial purposes is not allowed**.

Please cite the datasets in any publication or presentation using this project.
